{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yosJR56zsn72"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import DataLoader\n","import SimpleITK as sitk\n","import torchio as tio\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEl9ks2Ysn73"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv3d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3,3,3),\n","            stride=(1, 1, 1),\n","            padding=(1, 1, 1)\n","        )\n","\n","        self.conv2 = nn.Conv3d(\n","            in_channels=out_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3,3,3),\n","            stride=(1, 1, 1),\n","            padding=(1, 1, 1)\n","        )\n","\n","        self.batch_norm = nn.BatchNorm3d(out_channels)\n","        self.leaky_relu = nn.LeakyReLU()\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.batch_norm(x)\n","        x = self.leaky_relu(x)\n","        return x\n","\n","\n","class Analysis(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.encoder1 = Encoder(1, 26)\n","        self.encoder2 = Encoder(26, 52)\n","        self.encoder3 = Encoder(52, 104)\n","        self.encoder4 = Encoder(104, 208)\n","        self.encoder5 = Encoder(208, 416)\n","        self.pool = nn.MaxPool3d((1,2,2))\n","\n","\n","    def forward(self, x):\n","        x1 = self.encoder1(x)\n","        x1_pool = self.pool(x1)\n","\n","        x2 = self.encoder2(x1_pool)\n","        x2_pool = self.pool(x2)\n","\n","        x3 = self.encoder3(x2_pool)\n","        x3_pool = self.pool(x3)\n","\n","        x4 = self.encoder4(x3_pool)\n","        x4_pool = self.pool(x4)\n","\n","        x5 = self.encoder5(x4_pool)\n","\n","        return [x1, x2, x3, x4, x5]\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.up = nn.ConvTranspose3d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=(1,2,2),\n","            stride=(1,2,2),\n","        )\n","\n","        self.conv1 = nn.Conv3d(\n","            in_channels=out_channels * 2,\n","            out_channels=out_channels,\n","            kernel_size=(3,3,3),\n","            stride=(1, 1, 1),\n","            padding=(1, 1, 1)\n","        )\n","\n","        self.conv2 = nn.Conv3d(\n","            in_channels=out_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3,3,3),\n","            stride=(1, 1, 1),\n","            padding=(1, 1, 1)\n","        )\n","\n","        self.batch_norm = nn.BatchNorm3d(out_channels)\n","        self.leaky_relu = nn.LeakyReLU()\n","\n","\n","    def forward(self, x, x_encoder):\n","        x = self.up(x)\n","        x = torch.cat([x, x_encoder], dim=1)\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.batch_norm(x)\n","        x = self.leaky_relu(x)\n","        return x\n","\n","\n","class Synthesis(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.decoder1 = Decoder(416, 208)\n","        self.decoder2 = Decoder(208, 104)\n","        self.decoder3 = Decoder(104, 52)\n","        self.decoder4 = Decoder(52, 26)\n","\n","        self.up1 = nn.ConvTranspose3d(\n","            in_channels=104,\n","            out_channels=52,\n","            kernel_size=(1, 2, 2),\n","            stride=(1,2,2),\n","        )\n","\n","        self.up2 = nn.ConvTranspose3d(\n","            in_channels=52,\n","            out_channels=26,\n","            kernel_size=(1, 2,2),\n","            stride=(1,2,2),\n","        )\n","\n","\n","    def forward(self, x, x_encoder):\n","        x1 = self.decoder1(x, x_encoder[3])\n","\n","        x2 = self.decoder2(x1, x_encoder[2])\n","        x3 = self.decoder3(x2, x_encoder[1])\n","        x4 = self.decoder4(x3, x_encoder[0])\n","        z = self.up2(x3 + self.up1(x2))\n","\n","        return x4 + z\n","\n","\n","\n","class UNet3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.analysis = Analysis()\n","        self.synthesis = Synthesis()\n","\n","        self.conv_last = nn.Conv3d(\n","            in_channels=26,\n","            out_channels=3,\n","            kernel_size=(1,1,1),\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","\n","\n","    def forward(self, x):\n","        x_encoder = self.analysis(x)\n","        output = self.synthesis(x_encoder[4], x_encoder)\n","\n","        output = self.conv_last(output)\n","        output = self.sigmoid(output)\n","        return output\n","\n","\n","def load_data(img_path, gt_path):\n","    \"\"\"\n","    Parameter:\n","        img_path: file nii.gz\n","        gt_path: ground truth file nii.gz\n","    \"\"\"\n","    obj_ids = torch.tensor([1,2,3]).to(torch.long)\n","\n","    img = sitk.ReadImage(img_path)\n","    gt = sitk.ReadImage(gt_path)\n","\n","    img = sitk.GetArrayFromImage(img)\n","    gt = sitk.GetArrayFromImage(gt)\n","\n","    img = torch.tensor(img).unsqueeze(0)\n","    gt = torch.tensor(gt).unsqueeze(0)\n","\n","    gt = (gt == obj_ids[:,None,None,None])\n","    num_layers = img.size(1)\n","\n","    transform = tio.Compose([\n","        tio.Resize((num_layers, 352,352)),\n","        tio.CropOrPad((10, 224, 224)),\n","        tio.ZNormalization()\n","    ])\n","\n","    gt_transform = tio.Compose([\n","        tio.Resize((num_layers, 352,352)),\n","        tio.CropOrPad((10, 224, 224)),\n","    ])\n","\n","    img = transform(img)\n","    gt = gt_transform(gt).to(torch.long)\n","\n","    return img, gt\n","\n","def predict(img, gt, model_path):\n","    \"\"\"\n","    Parameter:\n","        img: tensor lấy từ hàm load_data\n","        gt: giống img\n","        model_path: .pth file\n","    \"\"\"\n","    model = UNet3D()\n","    model.load_state_dict(torch.load(model_path))\n","\n","    with torch.no_grad():\n","        output = model(img)\n","\n",""]}],"metadata":{"kernelspec":{"display_name":"ds13","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}